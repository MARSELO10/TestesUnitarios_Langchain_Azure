#!/usr/bin/env python3
"""
Sistema de Gera√ß√£o de Testes Unit√°rios com LangChain e Azure ChatGPT
Vers√£o simplificada e funcional

Autor: Edson Gomes
Email: edsgom@gmail.com
Bootcamp: DIO + BairesDev Machine Learning
Data: Janeiro 2025
"""

import os
import sys
import json
import logging
import ast
import re
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any
import argparse
from dotenv import load_dotenv

# Configura√ß√£o b√°sica de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SimulatedLLM:
    """LLM simulado para demonstra√ß√£o quando Azure n√£o est√° configurado."""
    
    def __init__(self):
        self.temperature = 0.1
    
    def invoke(self, prompt):
        """Simula uma resposta do LLM."""
        # Analisa o c√≥digo no prompt para gerar testes relevantes
        if "def " in prompt or "class " in prompt:
            return self._generate_mock_tests(prompt)
        return "# Testes simulados - Configure Azure OpenAI para funcionalidade completa"
    
    def _generate_mock_tests(self, prompt):
        """Gera testes simulados baseados no c√≥digo fornecido."""
        test_template = '''import pytest
import unittest
from unittest.mock import Mock, patch

# Testes gerados automaticamente (SIMULA√á√ÉO)
# Configure Azure OpenAI para gera√ß√£o real de testes

"""
Este √© um exemplo de como os testes seriam gerados.
Para funcionalidade completa, configure:
- AZURE_OPENAI_API_KEY
- AZURE_OPENAI_ENDPOINT 
- AZURE_OPENAI_DEPLOYMENT_NAME
"""

class TestGeneratedCode:
    """Classe de teste gerada automaticamente."""
    
    def setup_method(self):
        """Configura√ß√£o inicial dos testes."""
        pass
    
    def test_basic_functionality(self):
        """Teste b√°sico de funcionalidade."""
        # Este seria um teste real gerado pela IA
        assert True
    
    def test_edge_cases(self):
        """Teste de casos extremos."""
        # Casos de borda seriam testados aqui
        assert True
    
    def test_error_conditions(self):
        """Teste de condi√ß√µes de erro."""
        # Testes de exce√ß√µes seriam gerados aqui
        with pytest.raises(Exception):
            # C√≥digo que deve gerar exce√ß√£o
            pass

# Testes parametrizados seriam gerados automaticamente
@pytest.mark.parametrize("input_val,expected", [
    (1, 1),
    (2, 2),
    (3, 3),
])
def test_parametrized_function(input_val, expected):
    """Teste parametrizado de exemplo."""
    assert input_val == expected

if __name__ == "__main__":
    pytest.main([__file__])
'''
        return test_template

class ConfigManager:
    """Gerenciador de configura√ß√µes simplificado."""
    
    def __init__(self):
        """Inicializa configura√ß√µes."""
        load_dotenv()
        
        self.azure_config = {
            'api_key': os.getenv('AZURE_OPENAI_API_KEY', ''),
            'endpoint': os.getenv('AZURE_OPENAI_ENDPOINT', ''),
            'api_version': os.getenv('AZURE_OPENAI_API_VERSION', '2024-02-01'),
            'deployment_name': os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME', 'gpt-4'),
            'temperature': float(os.getenv('TEMPERATURE', '0.1')),
            'max_tokens': int(os.getenv('MAX_TOKENS', '2000'))
        }
        
        self.test_config = {
            'framework': os.getenv('TEST_FRAMEWORK', 'pytest'),
            'include_fixtures': os.getenv('INCLUDE_FIXTURES', 'true').lower() == 'true',
            'test_edge_cases': os.getenv('TEST_EDGE_CASES', 'true').lower() == 'true',
            'min_coverage': int(os.getenv('MIN_COVERAGE', '80'))
        }
        
        self.system_config = {
            'output_directory': os.getenv('OUTPUT_DIRECTORY', 'generated_tests'),
            'log_level': os.getenv('LOG_LEVEL', 'INFO'),
            'debug_mode': os.getenv('DEBUG_MODE', 'false').lower() == 'true'
        }
        
        # Verificar se est√° em modo simula√ß√£o
        self.simulate_mode = not (self.azure_config['api_key'] and 
                                 self.azure_config['endpoint'] and
                                 self.azure_config['api_key'] != 'sua_chave_azure_aqui')
    
    def create_directories(self):
        """Cria diret√≥rios necess√°rios."""
        Path(self.system_config['output_directory']).mkdir(exist_ok=True)
        Path('logs').mkdir(exist_ok=True)
        Path('metrics').mkdir(exist_ok=True)
    
    def get_config_summary(self):
        """Retorna resumo das configura√ß√µes."""
        return f"""
Configura√ß√µes do Sistema
=======================
Modo: {'Simula√ß√£o' if self.simulate_mode else 'Azure OpenAI'}
Framework: {self.test_config['framework']}
Cobertura M√≠nima: {self.test_config['min_coverage']}%
Diret√≥rio de Sa√≠da: {self.system_config['output_directory']}
Debug: {self.system_config['debug_mode']}
"""

class CodeAnalyzer:
    """Analisador de c√≥digo Python."""
    
    def __init__(self):
        """Inicializa o analisador."""
        pass
    
    def analyze_code(self, source_code: str) -> Dict[str, Any]:
        """Analisa c√≥digo Python e extrai informa√ß√µes."""
        try:
            tree = ast.parse(source_code)
            
            functions = []
            classes = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append({
                        'name': node.name,
                        'parameters': [arg.arg for arg in node.args.args],
                        'line': node.lineno,
                        'is_async': isinstance(node, ast.AsyncFunctionDef)
                    })
                elif isinstance(node, ast.ClassDef):
                    methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                    classes.append({
                        'name': node.name,
                        'methods': methods,
                        'line': node.lineno
                    })
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        imports.extend([alias.name for alias in node.names])
                    else:
                        module = node.module or ''
                        imports.extend([f"{module}.{alias.name}" for alias in node.names])
            
            statistics = {
                'total_functions': len(functions),
                'total_classes': len(classes),
                'total_methods': sum(len(cls['methods']) for cls in classes),
                'total_lines': len(source_code.splitlines()),
                'complexity': self._calculate_complexity(tree)
            }
            
            return {
                'functions': functions,
                'classes': classes,
                'imports': imports,
                'statistics': statistics,
                'recommendations': self._generate_recommendations(statistics)
            }
            
        except SyntaxError as e:
            return {'error': f'Erro de sintaxe: {e}'}
        except Exception as e:
            return {'error': f'Erro na an√°lise: {e}'}
    
    def _calculate_complexity(self, tree) -> int:
        """Calcula complexidade ciclom√°tica b√°sica."""
        complexity = 1  # Complexidade base
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(node, (ast.ExceptHandler, ast.With, ast.AsyncWith)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        
        return complexity
    
    def _generate_recommendations(self, stats: Dict) -> List[str]:
        """Gera recomenda√ß√µes baseadas nas estat√≠sticas."""
        recommendations = []
        
        if stats['complexity'] > 15:
            recommendations.append("Considere refatorar - complexidade alta detectada")
        
        if stats['total_functions'] == 0 and stats['total_classes'] == 0:
            recommendations.append("Nenhuma fun√ß√£o ou classe encontrada para testar")
        
        if stats['total_functions'] > 10:
            recommendations.append("Muitas fun√ß√µes - considere organizar em classes")
        
        return recommendations

def quick_analyze(source_code: str) -> Dict[str, Any]:
    """An√°lise r√°pida de c√≥digo."""
    try:
        tree = ast.parse(source_code)
        functions = len([n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)])
        classes = len([n for n in ast.walk(tree) if isinstance(n, ast.ClassDef)])
        return {'functions': functions, 'classes': classes}
    except:
        return {'error': 'C√≥digo inv√°lido'}

class TestValidator:
    """Validador de testes gerados."""
    
    def __init__(self):
        """Inicializa o validador."""
        pass
    
    def validate_test_code(self, test_code: str) -> Dict[str, Any]:
        """Valida c√≥digo de teste."""
        try:
            tree = ast.parse(test_code)
            
            test_functions = []
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef) and node.name.startswith('test_'):
                    test_functions.append(node.name)
            
            return {
                'is_valid': True,
                'test_count': len(test_functions),
                'test_functions': test_functions,
                'coverage_score': min(len(test_functions) * 10, 100),
                'issues': []
            }
        except Exception as e:
            return {
                'is_valid': False,
                'error': str(e),
                'test_count': 0,
                'coverage_score': 0
            }

class TestGeneratorAgent:
    """Agente principal para gera√ß√£o de testes."""
    
    def __init__(self, config_manager: ConfigManager):
        """Inicializa o agente."""
        self.config = config_manager
        self.analyzer = CodeAnalyzer()
        self.validator = TestValidator()
        
        if self.config.simulate_mode:
            self.llm = SimulatedLLM()
            logger.info("Modo simula√ß√£o ativado")
        else:
            try:
                from langchain_openai import AzureChatOpenAI
                self.llm = AzureChatOpenAI(**self.config.azure_config)
                logger.info("Azure OpenAI configurado")
            except ImportError:
                logger.warning("LangChain n√£o instalado, usando simula√ß√£o")
                self.llm = SimulatedLLM()
                self.config.simulate_mode = True
    
    def generate_tests(self, source_code: str) -> Dict[str, Any]:
        """Gera testes para c√≥digo fornecido."""
        try:
            # Analisar c√≥digo
            code_analysis = self.analyzer.analyze_code(source_code)
            
            if 'error' in code_analysis:
                return {
                    'success': False,
                    'error': code_analysis['error']
                }
            
            # Gerar prompt
            prompt = self._create_generation_prompt(source_code, code_analysis)
            
            # Gerar testes
            test_code = self.llm.invoke(prompt)
            
            # Validar testes
            validation = self.validator.validate_test_code(test_code)
            
            return {
                'success': True,
                'test_code': test_code,
                'code_analysis': code_analysis,
                'validation': validation,
                'simulate_mode': self.config.simulate_mode
            }
            
        except Exception as e:
            logger.error(f"Erro na gera√ß√£o de testes: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _create_generation_prompt(self, source_code: str, analysis: Dict) -> str:
        """Cria prompt para gera√ß√£o de testes."""
        stats = analysis['statistics']
        
        prompt = f"""
Voc√™ √© um especialista em testes unit√°rios Python. Analise o c√≥digo fornecido e gere testes completos usando {self.config.test_config['framework']}.

C√ìDIGO A TESTAR:
{source_code}

ESTAT√çSTICAS:
- Fun√ß√µes: {stats['total_functions']}
- Classes: {stats['total_classes']}
- Complexidade: {stats['complexity']}

REQUISITOS:
1. Use {self.config.test_config['framework']} como framework
2. Inclua testes para casos normais e extremos
3. Teste tratamento de exce√ß√µes
4. Adicione fixtures se necess√°rio
5. Use parametriza√ß√£o quando apropriado
6. Cobertura m√≠nima: {self.config.test_config['min_coverage']}%

GERE TESTES COMPLETOS E FUNCIONAIS:
"""
        return prompt
    
    def batch_generate_tests(self, code_files: List[tuple]) -> Dict[str, Any]:
        """Gera testes para m√∫ltiplos arquivos."""
        results = []
        successful = 0
        failed = 0
        start_time = datetime.now()
        
        for file_path, source_code in code_files:
            logger.info(f"Processando: {file_path}")
            
            result = self.generate_tests(source_code)
            result['file_path'] = file_path
            results.append(result)
            
            if result['success']:
                successful += 1
            else:
                failed += 1
        
        total_time = (datetime.now() - start_time).total_seconds()
        
        return {
            'results': results,
            'summary': {
                'total_files': len(code_files),
                'successful': successful,
                'failed': failed,
                'total_execution_time': total_time
            }
        }
    
    def improve_existing_tests(self, test_code: str, original_code: str) -> Dict[str, Any]:
        """Melhora testes existentes."""
        try:
            # Analisar c√≥digo original e testes atuais
            code_analysis = self.analyzer.analyze_code(original_code)
            test_validation = self.validator.validate_test_code(test_code)
            
            # Criar prompt para melhoria
            prompt = f"""
Analise os testes existentes e o c√≥digo original. Melhore os testes adicionando:
1. Casos de teste ausentes
2. Melhor cobertura
3. Testes de edge cases
4. Corre√ß√£o de problemas

C√ìDIGO ORIGINAL:
{original_code}

TESTES ATUAIS:
{test_code}

GERE VERS√ÉO MELHORADA DOS TESTES:
"""
            
            improved_tests = self.llm.invoke(prompt)
            new_validation = self.validator.validate_test_code(improved_tests)
            
            return {
                'success': True,
                'improved_tests': improved_tests,
                'improvements': {
                    'coverage_improvement': new_validation['coverage_score'] - test_validation['coverage_score'],
                    'new_test_count': new_validation['test_count'] - test_validation['test_count'],
                    'issues_resolved': len(test_validation.get('issues', []))
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

class TestGeneratorCLI:
    """Interface de linha de comando principal."""
    
    def __init__(self):
        """Inicializa a CLI."""
        self.config_manager = ConfigManager()
        self.agent = TestGeneratorAgent(self.config_manager)
        self.statistics = {
            'total_generations': 0,
            'successful_generations': 0,
            'failed_generations': 0,
            'start_time': datetime.now()
        }
        
        # Criar diret√≥rios
        self.config_manager.create_directories()
    
    def display_banner(self):
        """Exibe banner do sistema."""
        banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                     SISTEMA DE GERA√á√ÉO DE TESTES UNIT√ÅRIOS                  ‚ïë
‚ïë                          LangChain + Azure ChatGPT                          ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  Desenvolvido por: Edson Gomes                                              ‚ïë
‚ïë  Bootcamp: DIO + BairesDev Machine Learning                                 ‚ïë
‚ïë  GitHub: @edsongom1                                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """
        print(banner)
        
        if self.config_manager.simulate_mode:
            print("‚ö†Ô∏è  MODO SIMULA√á√ÉO ATIVO")
            print("   Configure as vari√°veis Azure OpenAI para usar o modo completo")
        
        print()
    
    def display_main_menu(self):
        """Exibe menu principal."""
        print("OP√á√ïES DISPON√çVEIS:")
        print("‚îÄ" * 50)
        print("1. üìù Gerar testes para c√≥digo Python")
        print("2. üìÅ Processar arquivo(s) de c√≥digo")
        print("3. üîç Analisar c√≥digo (sem gerar testes)")
        print("4. ‚ú® Melhorar testes existentes")
        print("5. ‚öôÔ∏è  Configura√ß√µes do sistema")
        print("6. üìä Estat√≠sticas e relat√≥rios")
        print("7. üß™ Executar exemplo de demonstra√ß√£o")
        print("8. ‚ùì Ajuda e documenta√ß√£o")
        print("9. üö™ Sair")
        print()
    
    def get_user_choice(self, max_option: int = 9) -> int:
        """Obt√©m escolha do usu√°rio."""
        while True:
            try:
                choice = input(f"Escolha uma op√ß√£o (1-{max_option}): ").strip()
                choice_int = int(choice)
                if 1 <= choice_int <= max_option:
                    return choice_int
                else:
                    print(f"‚ùå Por favor, escolha um n√∫mero entre 1 e {max_option}")
            except ValueError:
                print("‚ùå Por favor, digite um n√∫mero v√°lido")
            except KeyboardInterrupt:
                print("\n\nüëã Programa interrompido pelo usu√°rio")
                sys.exit(0)
    
    def run(self):
        """Executa o loop principal da CLI."""
        self.display_banner()
        
        while True:
            self.display_main_menu()
            choice = self.get_user_choice(9)
            
            if choice == 1:
                self.generate_tests_interactive()
            elif choice == 2:
                self.process_files()
            elif choice == 3:
                self.analyze_code_only()
            elif choice == 4:
                self.improve_existing_tests()
            elif choice == 5:
                self.show_system_configuration()
            elif choice == 6:
                self.show_statistics()
            elif choice == 7:
                self.run_demonstration()
            elif choice == 8:
                self.show_help()
            elif choice == 9:
                self._safe_exit()
                break
    
    def generate_tests_interactive(self):
        """Gera testes de forma interativa."""
        print("\n" + "=" * 60)
        print("üìù GERA√á√ÉO DE TESTES INTERATIVA")
        print("=" * 60)
        
        print("\nCole ou digite seu c√≥digo Python abaixo.")
        print("Para finalizar a entrada, digite 'END' em uma linha separada:")
        print("‚îÄ" * 40)
        
        code_lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == 'END':
                    break
                code_lines.append(line)
            except KeyboardInterrupt:
                print("\n‚ùå Entrada cancelada pelo usu√°rio")
                return
        
        source_code = '\n'.join(code_lines).strip()
        
        if not source_code:
            print("‚ùå Nenhum c√≥digo fornecido")
            return
        
        # An√°lise r√°pida
        quick_stats = quick_analyze(source_code)
        if 'error' in quick_stats:
            print("‚ùå C√≥digo com erro de sintaxe")
            return
        
        print(f"\nüîç C√≥digo analisado: {quick_stats['functions']} fun√ß√µes, {quick_stats['classes']} classes")
        
        # Confirmar gera√ß√£o
        confirm = input("Continuar com a gera√ß√£o de testes? (S/n): ").strip().lower()
        if confirm in ['n', 'no', 'n√£o']:
            print("‚ùå Gera√ß√£o cancelada")
            return
        
        print("\nüîÑ Gerando testes...")
        self._process_code_generation(source_code)
    
    def process_files(self):
        """Processa arquivos de c√≥digo."""
        print("\n" + "=" * 60)
        print("üìÅ PROCESSAMENTO DE ARQUIVOS")
        print("=" * 60)
        
        print("\nOp√ß√µes:")
        print("1. Processar arquivo √∫nico")
        print("2. Processar diret√≥rio")
        print("3. Voltar ao menu principal")
        
        choice = self.get_user_choice(3)
        
        if choice == 1:
            self._process_single_file()
        elif choice == 2:
            self._process_directory()
    
    def _process_single_file(self):
        """Processa um arquivo √∫nico."""
        file_path = input("\nüìÑ Caminho do arquivo Python (.py): ").strip()
        
        if not file_path:
            print("‚ùå Caminho n√£o fornecido")
            return
        
        path = Path(file_path)
        
        if not path.exists():
            print(f"‚ùå Arquivo n√£o encontrado: {file_path}")
            return
        
        if not path.suffix == '.py':
            print("‚ùå Arquivo deve ter extens√£o .py")
            return
        
        try:
            source_code = path.read_text(encoding='utf-8')
            print(f"‚úÖ Arquivo carregado: {path.name}")
            
            self._process_code_generation(source_code, path.stem)
            
        except Exception as e:
            print(f"‚ùå Erro ao ler arquivo: {e}")
    
    def _process_directory(self):
        """Processa diret√≥rio com arquivos Python."""
        dir_path = input("\nüìÅ Caminho do diret√≥rio: ").strip()
        
        if not dir_path:
            print("‚ùå Caminho n√£o fornecido")
            return
        
        path = Path(dir_path)
        
        if not path.exists() or not path.is_dir():
            print(f"‚ùå Diret√≥rio n√£o encontrado: {dir_path}")
            return
        
        # Encontrar arquivos Python
        py_files = list(path.glob("**/*.py"))
        
        if not py_files:
            print("‚ùå Nenhum arquivo Python encontrado")
            return
        
        print(f"üìÑ Encontrados {len(py_files)} arquivo(s) Python:")
        for i, file in enumerate(py_files[:10], 1):
            print(f"  {i}. {file.name}")
        
        if len(py_files) > 10:
            print(f"  ... e mais {len(py_files) - 10} arquivo(s)")
        
        confirm = input(f"\nProcessar {len(py_files)} arquivo(s)? (S/n): ").strip().lower()
        if confirm in ['n', 'no', 'n√£o']:
            return
        
        # Processar em lote
        code_files = []
        for file_path in py_files:
            try:
                source_code = file_path.read_text(encoding='utf-8')
                code_files.append((str(file_path), source_code))
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao ler {file_path.name}: {e}")
        
        if code_files:
            print(f"\nüîÑ Processando {len(code_files)} arquivo(s)...")
            self._process_batch_generation(code_files)
    
    def _process_code_generation(self, source_code: str, filename: Optional[str] = None):
        """Processa gera√ß√£o de testes para c√≥digo."""
        start_time = datetime.now()
        
        try:
            result = self.agent.generate_tests(source_code)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            print(f"\n{'‚úÖ' if result['success'] else '‚ùå'} Gera√ß√£o {'conclu√≠da' if result['success'] else 'falhou'}")
            print(f"‚è±Ô∏è  Tempo de execu√ß√£o: {execution_time:.2f}s")
            
            if result['success']:
                # Mostrar estat√≠sticas
                stats = result['code_analysis'].get('statistics', {})
                validation = result['validation']
                
                print(f"üìä Estat√≠sticas:")
                print(f"   Fun√ß√µes: {stats.get('total_functions', 0)}")
                print(f"   Classes: {stats.get('total_classes', 0)}")
                print(f"   Testes gerados: {validation.get('test_count', 0)}")
                print(f"   Cobertura estimada: {validation.get('coverage_score', 0):.1f}%")
                
                # Mostrar c√≥digo dos testes
                self._display_generated_tests(result['test_code'])
                
                # Op√ß√£o de salvar
                self._offer_save_tests(result['test_code'], filename)
                
                self.statistics['successful_generations'] += 1
            else:
                print(f"üí• Erro: {result['error']}")
                self.statistics['failed_generations'] += 1
                
            self.statistics['total_generations'] += 1
            
        except Exception as e:
            print(f"‚ùå Erro inesperado: {e}")
            self.statistics['failed_generations'] += 1
            self.statistics['total_generations'] += 1
    
    def _process_batch_generation(self, code_files: List[tuple]):
        """Processa gera√ß√£o em lote."""
        try:
            batch_result = self.agent.batch_generate_tests(code_files)
            
            summary = batch_result['summary']
            print(f"\nüìä RESULTADO DO PROCESSAMENTO EM LOTE")
            print(f"=" * 50)
            print(f"Total de arquivos: {summary['total_files']}")
            print(f"Sucessos: {summary['successful']}")
            print(f"Falhas: {summary['failed']}")
            print(f"Tempo total: {summary['total_execution_time']:.2f}s")
            
            # Atualizar estat√≠sticas
            self.statistics['successful_generations'] += summary['successful']
            self.statistics['failed_generations'] += summary['failed']
            self.statistics['total_generations'] += summary['total_files']
            
        except Exception as e:
            print(f"‚ùå Erro no processamento em lote: {e}")
    
    def analyze_code_only(self):
        """Analisa c√≥digo sem gerar testes."""
        print("\n" + "=" * 60)
        print("üîç AN√ÅLISE DE C√ìDIGO")
        print("=" * 60)
        
        print("\nCole seu c√≥digo Python abaixo (digite 'END' para finalizar):")
        
        code_lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == 'END':
                    break
                code_lines.append(line)
            except KeyboardInterrupt:
                print("\n‚ùå An√°lise cancelada")
                return
        
        source_code = '\n'.join(code_lines).strip()
        
        if not source_code:
            print("‚ùå Nenhum c√≥digo fornecido")
            return
        
        try:
            analyzer = CodeAnalyzer()
            analysis = analyzer.analyze_code(source_code)
            
            if 'error' in analysis:
                print(f"‚ùå Erro na an√°lise: {analysis['error']}")
                return
            
            self._display_code_analysis(analysis)
            
        except Exception as e:
            print(f"‚ùå Erro inesperado na an√°lise: {e}")
    
    def improve_existing_tests(self):
        """Melhora testes existentes."""
        print("\n" + "=" * 60)
        print("‚ú® MELHORIA DE TESTES EXISTENTES")
        print("=" * 60)
        
        print("\nEsta funcionalidade requer c√≥digo original e testes existentes.")
        print("Cole o c√≥digo original primeiro (digite 'END' para finalizar):")
        
        original_lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == 'END':
                    break
                original_lines.append(line)
            except KeyboardInterrupt:
                print("\n‚ùå Melhoria cancelada")
                return
        
        original_code = '\n'.join(original_lines).strip()
        
        if not original_code:
            print("‚ùå Nenhum c√≥digo original fornecido")
            return
        
        print("\nAgora cole os testes existentes (digite 'END' para finalizar):")
        
        test_lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == 'END':
                    break
                test_lines.append(line)
            except KeyboardInterrupt:
                print("\n‚ùå Melhoria cancelada")
                return
        
        test_code = '\n'.join(test_lines).strip()
        
        if not test_code:
            print("‚ùå Nenhum c√≥digo de teste fornecido")
            return
        
        self._process_test_improvement(test_code, original_code)
    
    def _process_test_improvement(self, test_code: str, original_code: str):
        """Processa melhoria de testes."""
        print("\nüîÑ Processando melhoria de testes...")
        
        try:
            result = self.agent.improve_existing_tests(test_code, original_code)
            
            if result['success']:
                print("‚úÖ Testes melhorados com sucesso!")
                
                improvements = result['improvements']
                print(f"\nüìà Melhorias:")
                print(f"  Cobertura: +{improvements['coverage_improvement']:.1f}%")
                print(f"  Problemas resolvidos: {improvements['issues_resolved']}")
                print(f"  Novos testes: {improvements['new_test_count']}")
                
                # Mostrar testes melhorados
                self._display_generated_tests(result['improved_tests'])
                
                # Op√ß√£o de salvar
                self._offer_save_tests(result['improved_tests'], "improved_tests")
                
            else:
                print(f"‚ùå Erro na melhoria: {result['error']}")
                
        except Exception as e:
            print(f"‚ùå Erro inesperado: {e}")
    
    def show_system_configuration(self):
        """Mostra configura√ß√µes do sistema."""
        print("\n" + "=" * 60)
        print("‚öôÔ∏è CONFIGURA√á√ïES DO SISTEMA")
        print("=" * 60)
        
        print(self.config_manager.get_config_summary())
        
        if self.config_manager.simulate_mode:
            print("\nüîß Para ativar Azure OpenAI, configure:")
            print("  - AZURE_OPENAI_API_KEY=sua_chave")
            print("  - AZURE_OPENAI_ENDPOINT=https://seu-recurso.openai.azure.com/")
            print("  - AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4")
    
    def show_statistics(self):
        """Mostra estat√≠sticas e relat√≥rios."""
        print("\n" + "=" * 60)
        print("üìä ESTAT√çSTICAS E RELAT√ìRIOS")
        print("=" * 60)
        
        # Calcular tempo de execu√ß√£o
        runtime = datetime.now() - self.statistics['start_time']
        success_rate = 0
        if self.statistics['total_generations'] > 0:
            success_rate = (self.statistics['successful_generations'] / 
                          self.statistics['total_generations']) * 100
        
        print(f"\nüìà ESTAT√çSTICAS GERAIS:")
        print(f"   Tempo de execu√ß√£o: {str(runtime).split('.')[0]}")
        print(f"   Total de gera√ß√µes: {self.statistics['total_generations']}")
        print(f"   Gera√ß√µes bem-sucedidas: {self.statistics['successful_generations']}")
        print(f"   Gera√ß√µes falharam: {self.statistics['failed_generations']}")
        print(f"   Taxa de sucesso: {success_rate:.1f}%")
    
    def run_demonstration(self):
        """Executa exemplo de demonstra√ß√£o."""
        print("\n" + "=" * 60)
        print("üß™ DEMONSTRA√á√ÉO DO SISTEMA")
        print("=" * 60)
        
        demo_code = '''def calcular_area_retangulo(largura, altura):
    """Calcula a √°rea de um ret√¢ngulo."""
    if largura <= 0 or altura <= 0:
        raise ValueError("Largura e altura devem ser positivas")
    return largura * altura

def calcular_perimetro_retangulo(largura, altura):
    """Calcula o per√≠metro de um ret√¢ngulo."""
    if largura <= 0 or altura <= 0:
        raise ValueError("Largura e altura devem ser positivas")
    return 2 * (largura + altura)

class ContaBancaria:
    def __init__(self, saldo_inicial=0):
        if saldo_inicial < 0:
            raise ValueError("Saldo inicial n√£o pode ser negativo")
        self._saldo = saldo_inicial
    
    def depositar(self, valor):
        if valor <= 0:
            raise ValueError("Valor deve ser positivo")
        self._saldo += valor
        return self._saldo
    
    def sacar(self, valor):
        if valor <= 0:
            raise ValueError("Valor deve ser positivo")
        if valor > self._saldo:
            raise ValueError("Saldo insuficiente")
        self._saldo -= valor
        return self._saldo
    
    @property
    def saldo(self):
        return self._saldo'''
        
        print("C√≥digo de demonstra√ß√£o:")
        print("‚îÄ" * 30)
        print(demo_code[:300] + "..." if len(demo_code) > 300 else demo_code)
        print("‚îÄ" * 30)
        
        confirm = input("\nProsseguir com a demonstra√ß√£o? (S/n): ").strip().lower()
        if confirm in ['n', 'no', 'n√£o']:
            return
        
        print("\nüîÑ Gerando testes de demonstra√ß√£o...")
        self._process_code_generation(demo_code, "demo")
    
    def show_help(self):
        """Mostra ajuda e documenta√ß√£o."""
        print("\n" + "=" * 60)
        print("‚ùì AJUDA E DOCUMENTA√á√ÉO")
        print("=" * 60)
        
        help_text = """
COMO USAR O SISTEMA:

1. üìù GERAR TESTES INTERATIVAMENTE:
   - Cole seu c√≥digo Python
   - Digite 'END' para finalizar
   - O sistema analisar√° e gerar√° testes automaticamente

2. üìÅ PROCESSAR ARQUIVOS:
   - Especifique arquivo √∫nico ou diret√≥rio
   - Suporte para processamento em lote
   - Resultados salvos automaticamente

3. üîç AN√ÅLISE DE C√ìDIGO:
   - Apenas analisa sem gerar testes
   - Identifica fun√ß√µes, classes e complexidade

4. ‚ú® MELHORAR TESTES EXISTENTES:
   - Analisa testes atuais
   - Sugere melhorias de cobertura
   - Adiciona casos de teste ausentes

CONFIGURA√á√ÉO AZURE (opcional):
- AZURE_OPENAI_API_KEY: Sua chave de API
- AZURE_OPENAI_ENDPOINT: URL do endpoint
- AZURE_OPENAI_DEPLOYMENT_NAME: Nome do modelo

MODO SIMULA√á√ÉO:
- Funciona sem Azure OpenAI
- Gera templates de teste b√°sicos
- Ideal para testes e demonstra√ß√µes

SUPORTE:
- GitHub: @edsongom1
- Email: edsgom@gmail.com
        """
        
        print(help_text)
    
    def _display_generated_tests(self, test_code: str):
        """Mostra c√≥digo dos testes gerados."""
        print(f"\nüß™ C√ìDIGO DOS TESTES GERADOS:")
        print("‚îÄ" * 60)
        
        # Limitar exibi√ß√£o se muito longo
        if len(test_code) > 1500:
            print(test_code[:1500])
            print(f"\n... (c√≥digo truncado - {len(test_code)} caracteres totais)")
            
            show_full = input("\nMostrar c√≥digo completo? (s/N): ").strip().lower()
            if show_full in ['s', 'sim', 'y', 'yes']:
                print(test_code)
        else:
            print(test_code)
        
        print("‚îÄ" * 60)
    
    def _display_code_analysis(self, analysis: Dict):
        """Exibe an√°lise detalhada do c√≥digo."""
        print(f"\nüîç AN√ÅLISE DETALHADA DO C√ìDIGO:")
        print("‚îÄ" * 50)
        
        # Estat√≠sticas gerais
        stats = analysis.get('statistics', {})
        print(f"üìä Estat√≠sticas:")
        print(f"   Fun√ß√µes encontradas: {stats.get('total_functions', 0)}")
        print(f"   Classes encontradas: {stats.get('total_classes', 0)}")
        print(f"   M√©todos encontrados: {stats.get('total_methods', 0)}")
        print(f"   Linhas de c√≥digo: {stats.get('total_lines', 0)}")
        print(f"   Complexidade ciclom√°tica: {stats.get('complexity', 0)}")
        
        # Fun√ß√µes encontradas
        functions = analysis.get('functions', [])
        if functions:
            print(f"\nüìã Fun√ß√µes ({len(functions)}):")
            for func in functions:
                visibility = "üîí" if func['name'].startswith('_') else "üîì"
                params = ', '.join(func['parameters'])
                print(f"   {visibility} {func['name']}({params})")
        
        # Classes encontradas
        classes = analysis.get('classes', [])
        if classes:
            print(f"\nüì¶ Classes ({len(classes)}):")
            for cls in classes:
                print(f"   üèóÔ∏è  {cls['name']}")
                if cls['methods']:
                    for method in cls['methods'][:3]:
                        visibility = "üîí" if method.startswith('_') else "üîì"
                        print(f"      {visibility} {method}()")
                    if len(cls['methods']) > 3:
                        print(f"      ... e mais {len(cls['methods']) - 3} m√©todo(s)")
        
        # Imports encontrados
        imports = analysis.get('imports', [])
        if imports:
            print(f"\nüì• Imports ({len(imports)}):")
            for imp in imports[:5]:
                print(f"   üì¶ {imp}")
            if len(imports) > 5:
                print(f"   ... e mais {len(imports) - 5} import(s)")
        
        # Recomenda√ß√µes
        recommendations = analysis.get('recommendations', [])
        if recommendations:
            print(f"\nüí° Recomenda√ß√µes:")
            for rec in recommendations:
                print(f"   ‚Ä¢ {rec}")
    
    def _offer_save_tests(self, test_code: str, base_filename: Optional[str] = None):
        """Oferece op√ß√£o de salvar testes gerados."""
        save = input("\nüíæ Deseja salvar os testes em arquivo? (S/n): ").strip().lower()
        if save not in ['n', 'no', 'n√£o']:
            if base_filename:
                filename = f"test_{base_filename}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            else:
                filename = f"test_generated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            
            try:
                # Criar diret√≥rio de testes se n√£o existir
                test_dir = Path(self.config_manager.system_config['output_directory'])
                test_dir.mkdir(parents=True, exist_ok=True)
                
                file_path = test_dir / filename
                file_path.write_text(test_code, encoding='utf-8')
                print(f"‚úÖ Testes salvos em: {file_path}")
                    
            except Exception as e:
                print(f"‚ùå Erro ao salvar arquivo: {e}")
    
    def _safe_exit(self):
        """Sai do programa de forma segura."""
        print("\nüëã Finalizando sistema...")
        
        # Mostrar estat√≠sticas finais
        if self.statistics['total_generations'] > 0:
            runtime = datetime.now() - self.statistics['start_time']
            success_rate = (self.statistics['successful_generations'] / 
                          self.statistics['total_generations']) * 100
            
            print(f"üìä Estat√≠sticas da sess√£o:")
            print(f"   Tempo total: {str(runtime).split('.')[0]}")
            print(f"   Gera√ß√µes: {self.statistics['total_generations']}")
            print(f"   Taxa de sucesso: {success_rate:.1f}%")
        
        print("‚úÖ Sistema finalizado com sucesso")


def create_argument_parser():
    """Cria parser para argumentos de linha de comando."""
    parser = argparse.ArgumentParser(
        description='Sistema de Gera√ß√£o de Testes Unit√°rios com LangChain e Azure ChatGPT',
        epilog='Desenvolvido por Edson Gomes - Bootcamp DIO + BairesDev'
    )
    
    parser.add_argument(
        '--file', '-f',
        type=str,
        help='Arquivo Python para gerar testes'
    )
    
    parser.add_argument(
        '--directory', '-d',
        type=str,
        help='Diret√≥rio com arquivos Python para processar'
    )
    
    parser.add_argument(
        '--simulate',
        action='store_true',
        help='Executar em modo simula√ß√£o (sem Azure API)'
    )
    
    parser.add_argument(
        '--version', '-v',
        action='version',
        version='Sistema de Gera√ß√£o de Testes v1.0.0'
    )
    
    return parser


def process_command_line_args(args):
    """Processa argumentos de linha de comando."""
    cli = TestGeneratorCLI()
    
    if args.file:
        # Processar arquivo √∫nico
        file_path = Path(args.file)
        if file_path.exists() and file_path.suffix == '.py':
            source_code = file_path.read_text(encoding='utf-8')
            cli._process_code_generation(source_code, file_path.stem)
        else:
            print(f"‚ùå Arquivo n√£o encontrado ou inv√°lido: {args.file}")
            return 1
    
    elif args.directory:
        # Processar diret√≥rio
        dir_path = Path(args.directory)
        if dir_path.exists() and dir_path.is_dir():
            py_files = list(dir_path.glob("**/*.py"))
            if py_files:
                code_files = []
                for file_path in py_files:
                    try:
                        source_code = file_path.read_text(encoding='utf-8')
                        code_files.append((str(file_path), source_code))
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Erro ao ler {file_path}: {e}")
                
                if code_files:
                    cli._process_batch_generation(code_files)
            else:
                print(f"‚ùå Nenhum arquivo Python encontrado em: {args.directory}")
                return 1
        else:
            print(f"‚ùå Diret√≥rio n√£o encontrado: {args.directory}")
            return 1
    
    else:
        # Executar interface interativa
        cli.run()
    
    return 0


def main():
    """Fun√ß√£o principal do programa."""
    try:
        parser = create_argument_parser()
        args = parser.parse_args()
        
        # Processar argumentos ou executar interativamente
        exit_code = process_command_line_args(args)
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        print("\n\nüëã Programa interrompido pelo usu√°rio")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå Erro fatal: {e}")
        logger.error(f"Erro fatal: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
